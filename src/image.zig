//! Image processing module
//!
//! This module provides a unified interface to image processing functionality.
//! The main Image struct supports generic pixel types and provides operations for:
//! - Loading and saving images (PNG, JPEG)
//! - Terminal display with multiple formats (SGR, Braille, Sixel, Kitty)
//! - Geometric transforms (resize, rotate, crop, flip)
//! - Filters (blur, sharpen, edge detection)
//! - Views for zero-copy sub-image operations

const std = @import("std");
const assert = std.debug.assert;
const Allocator = std.mem.Allocator;

const Rgb = @import("color.zig").Rgb(u8);
const Rgba = @import("color.zig").Rgba(u8);
const Gray = @import("color.zig").Gray;
const convertColor = @import("color.zig").convertColor;
const Rectangle = @import("geometry.zig").Rectangle;
const Point = @import("geometry/Point.zig").Point;
const jpeg = @import("jpeg.zig");
const png = @import("png.zig");
const metrics = @import("image/metrics.zig");

// Import image sub-modules (private for internal use)
const DisplayFormatter = @import("image/display.zig").DisplayFormatter;
const Edges = @import("image/edges.zig").Edges;
const Enhancement = @import("image/enhancement.zig").Enhancement;
const binary = @import("image/binary.zig");
const Transform = @import("image/transforms.zig").Transform;
const interpolation = @import("image/interpolation.zig");
const OrderStatisticBlurOps = @import("image/order_statistic_blur.zig").OrderStatisticBlurOps;

pub const DisplayFormat = @import("image/display.zig").DisplayFormat;
pub const ImageFormat = @import("image/format.zig").ImageFormat;
pub const Interpolation = @import("image/interpolation.zig").Interpolation;
pub const PixelIterator = @import("image/PixelIterator.zig").PixelIterator;
pub const ShenCastan = @import("image/ShenCastan.zig");
pub const Histogram = @import("image/histogram.zig").Histogram;
pub const BinaryKernel = binary.Kernel;
const convolution = @import("image/convolution.zig");
pub const BorderMode = convolution.BorderMode;
pub const MotionBlur = @import("image/motion_blur.zig").MotionBlur;
const MotionBlurOps = @import("image/motion_blur.zig").MotionBlurOps;
const Blending = @import("blending.zig").Blending;

/// Assigns `sample` into `dest`, applying blending when requested and converting
/// between color spaces as needed. `dest` must be a pointer to the pixel to
/// modify. When `sample` is `Rgba` and a blend mode other than `.none` is
/// requested, the destination pixel is converted to `Rgba`, composited, and
/// converted back to the destination type. Otherwise the sample is converted to
/// the target type and stored directly.
pub inline fn assignPixel(dest: anytype, sample: anytype, blend_mode: Blending) void {
    comptime {
        const info = @typeInfo(@TypeOf(dest));
        if (info != .pointer) @compileError("assignPixel expects a pointer destination");
    }
    const DestType = std.meta.Child(@TypeOf(dest));
    const SrcType = @TypeOf(sample);

    if (comptime SrcType == Rgba) {
        if (blend_mode != .none) {
            const rgba_sample: Rgba = sample;
            if (comptime DestType == Rgba) {
                dest.* = dest.blend(rgba_sample, blend_mode);
            } else {
                const dst_rgba = convertColor(Rgba, dest.*);
                const blended = dst_rgba.blend(rgba_sample, blend_mode);
                dest.* = convertColor(DestType, blended);
            }
            return;
        }
    }

    if (comptime SrcType == DestType) {
        dest.* = sample;
    } else {
        dest.* = convertColor(DestType, sample);
    }
}

/// A simple image struct that encapsulates the size and the data.
pub fn Image(comptime T: type) type {
    return struct {
        rows: u32,
        cols: u32,
        data: []T,
        stride: usize,

        const Self = @This();

        /// Integral image operations for fast box filtering and region sums.
        pub const Integral = @import("image/integral.zig").Integral(T);

        /// Creates an empty image with zero dimensions, used as a placeholder for output parameters.
        /// When passed to functions like `rotateFrom()`, `blurBox()`, etc., the function will
        /// automatically allocate and size the image appropriately. This eliminates the need
        /// to pre-allocate or guess output dimensions.
        ///
        /// Example usage:
        /// ```zig
        /// var rotated: Image(u8) = .empty;
        /// try image.rotateFrom(allocator, center, angle, &rotated); // Auto-sizes to optimal dimensions
        /// defer rotated.deinit(allocator);
        /// ```
        pub const empty: Self = .{ .rows = 0, .cols = 0, .data = &[_]T{}, .stride = 0 };

        /// Constructs an image of rows and cols size allocating its own memory.
        /// The image owns the memory and deinit should be called to free it.
        pub fn init(allocator: Allocator, rows: u32, cols: u32) !Image(T) {
            const pixel_count = try std.math.mul(usize, rows, cols);
            return .{
                .rows = rows,
                .cols = cols,
                .data = try allocator.alloc(T, pixel_count),
                .stride = cols,
            };
        }

        /// Constructs an image with the same dimensions as the reference image.
        /// The image owns the memory and deinit should be called to free it.
        ///
        /// Example usage:
        /// ```zig
        /// var blurred = try Image(u8).initLike(allocator, original);
        /// defer blurred.deinit(allocator);
        /// try original.gaussianBlur(1.4, blurred);
        /// ```
        pub fn initLike(allocator: Allocator, reference: anytype) !Image(T) {
            return init(allocator, reference.rows, reference.cols);
        }

        /// Sets the image rows and cols to zero and frees the memory from the image.  It should
        /// only be called if the image owns the memory.
        pub fn deinit(self: *Self, allocator: Allocator) void {
            defer self.* = Self.empty;

            if (self.isOwned()) {
                allocator.free(self.data);
            }
        }

        /// Constructs an image of rows and cols size from an existing slice.
        pub fn initFromSlice(rows: u32, cols: u32, data: []T) Image(T) {
            const expected_len = std.math.mul(usize, rows, cols) catch @panic("Image.initFromSlice overflow");
            assert(data.len >= expected_len);
            return .{
                .rows = rows,
                .cols = cols,
                .data = data[0..expected_len],
                .stride = cols,
            };
        }

        /// Constructs an image of `rows` and `cols` size by reinterpreting the provided slice of `bytes` as a slice of `T`.
        /// The length of the `bytes` slice must be exactly `rows * cols * @sizeOf(T)`.
        pub fn initFromBytes(rows: u32, cols: u32, bytes: []u8) Image(T) {
            const expected_len = std.math.mul(usize, rows, cols) catch @panic("Image.initFromBytes overflow");
            const expected_bytes = std.math.mul(usize, expected_len, @sizeOf(T)) catch @panic("Image.initFromBytes overflow");
            assert(expected_bytes == bytes.len);
            return .{
                .rows = rows,
                .cols = cols,
                .data = @as([*]T, @ptrCast(@alignCast(bytes.ptr)))[0 .. bytes.len / @sizeOf(T)],
                .stride = cols,
            };
        }

        /// Returns true when this image appears to fully own its underlying buffer.
        /// The check is conservative: only contiguous buffers with the expected length
        /// (`rows * cols`) report true. Views, zero-sized placeholders, or images backed
        /// by external storage will return false.
        pub fn isOwned(self: Self) bool {
            if (self.data.len == 0) return false;
            if (self.rows == 0 or self.cols == 0) return false;
            if (self.stride != self.cols) return false;

            const expected_len = std.math.mul(usize, self.rows, self.cols) catch return false;
            return self.data.len == expected_len;
        }

        /// Fills the entire image with a solid value.
        /// Uses a fast memset when contiguous; otherwise fills row-by-row respecting stride.
        pub fn fill(self: Self, value: T) void {
            if (self.isContiguous()) {
                @memset(self.data, value);
            } else {
                // Respect stride when the image is a view
                for (0..self.rows) |r| {
                    const start = r * self.stride;
                    @memset(self.data[start .. start + self.cols], value);
                }
            }
        }

        /// Sets the border outside `rect` to `value` (rect is clipped to bounds).
        /// Efficiently fills only the top/bottom bands and left/right bands per row.
        pub fn setBorder(self: Self, rect: Rectangle(u32), value: T) void {
            const bounds = self.getRectangle();
            const inner = bounds.intersect(rect) orelse {
                self.fill(value);
                return;
            };

            // Top band [0, inner.t)
            var r: usize = 0;
            while (r < inner.t) : (r += 1) {
                const start = r * self.stride;
                @memset(self.data[start .. start + self.cols], value);
            }

            // Middle rows [inner.t, inner.b)
            r = inner.t;
            while (r < inner.b) : (r += 1) {
                const row_start = r * self.stride;
                if (inner.l > 0) {
                    @memset(self.data[row_start .. row_start + inner.l], value);
                }
                if (inner.r < self.cols) {
                    @memset(self.data[row_start + inner.r .. row_start + self.cols], value);
                }
            }

            // Bottom band [inner.b, rows)
            r = inner.b;
            while (r < self.rows) : (r += 1) {
                const start = r * self.stride;
                @memset(self.data[start .. start + self.cols], value);
            }
        }

        /// Returns the image data reinterpreted as a slice of bytes.
        /// Note: The image should not be a view; this is enforced by an assertion.
        pub fn asBytes(self: Self) []u8 {
            assert(self.rows * self.cols == self.data.len);
            assert(self.isContiguous());
            return @as([*]u8, @ptrCast(@alignCast(self.data.ptr)))[0 .. self.data.len * @sizeOf(T)];
        }

        /// Loads an image from a file with automatic format detection.
        /// Detects format based on file header signatures and calls the appropriate loader.
        ///
        /// Example usage:
        /// ```zig
        /// var img = try Image(Rgb).load(io, allocator, "photo.jpg");
        /// defer img.deinit(allocator);
        /// ```
        pub fn load(io: std.Io, allocator: Allocator, file_path: []const u8) !Self {
            const image_format = try ImageFormat.detectFromPath(io, allocator, file_path) orelse return error.UnsupportedImageFormat;

            return switch (image_format) {
                .png => png.load(T, io, allocator, file_path, .{}),
                .jpeg => jpeg.load(T, io, allocator, file_path, .{}),
            };
        }

        /// Loads an image from an in-memory byte buffer with automatic format detection.
        /// This is useful when image data comes from network streams or preloaded assets.
        ///
        /// Example usage:
        /// ```zig
        /// const bytes = try fetchNetworkImage();
        /// var img: Image(Rgb) = try .loadFromBytes(allocator, bytes);
        /// defer img.deinit(allocator);
        /// ```
        pub fn loadFromBytes(allocator: Allocator, data: []const u8) !Self {
            const image_format = ImageFormat.detectFromBytes(data) orelse return error.UnsupportedImageFormat;

            return switch (image_format) {
                .png => png.loadFromBytes(T, allocator, data, .{}),
                .jpeg => jpeg.loadFromBytes(T, allocator, data, .{}),
            };
        }

        /// Saves the image to a file in PNG format.
        /// Returns an error if the file path doesn't end in `.png` or `.PNG`.
        pub fn save(self: Self, io: std.Io, allocator: Allocator, file_path: []const u8) !void {
            if (std.ascii.endsWithIgnoreCase(file_path, ".png")) {
                try png.save(T, io, allocator, self, file_path);
            } else if (std.ascii.endsWithIgnoreCase(file_path, ".jpg") or std.ascii.endsWithIgnoreCase(file_path, ".jpeg")) {
                try jpeg.save(T, io, allocator, self, file_path);
            } else {
                return error.UnsupportedImageFormat;
            }
        }

        /// Returns the total number of pixels in the image (rows * cols).
        pub inline fn size(self: Self) usize {
            return @as(usize, self.rows) * @as(usize, self.cols);
        }

        /// Returns the number of channels or depth of this image type.
        pub fn channels() u32 {
            return comptime switch (@typeInfo(T)) {
                .int, .float => 1,
                .@"struct" => std.meta.fields(T).len,
                .array => |info| info.len,
                else => @compileError("Image(" ++ @typeName(T) ++ " is unsupported."),
            };
        }

        /// Returns true if and only if `self` and `other` have the same number of rows and columns.
        /// It does not compare pixel data or types.
        pub fn hasSameShape(self: Self, other: anytype) bool {
            return self.rows == other.rows and self.cols == other.cols;
        }

        /// Returns the bounding rectangle for the current image.
        pub fn getRectangle(self: Self) Rectangle(u32) {
            return .{ .l = 0, .t = 0, .r = self.cols, .b = self.rows };
        }

        /// Returns the center point of the image as a Point(2, f32).
        /// This is commonly used as the rotation center for image rotation.
        ///
        /// Example usage:
        /// ```zig
        /// try image.rotate(allocator, image.getCenter(), angle, &rotated);
        /// ```
        pub fn getCenter(self: Self) Point(2, f32) {
            return .init(.{
                @as(f32, @floatFromInt(self.cols)) / 2.0,
                @as(f32, @floatFromInt(self.rows)) / 2.0,
            });
        }

        /// Returns an image view with boundaries defined by `rect` within the image boundaries.
        /// The returned image references the memory of `self`, so there are no allocations
        /// or copies.
        pub fn view(self: Self, rect: Rectangle(u32)) Image(T) {
            const clipped = self.getRectangle().intersect(rect) orelse {
                return Self.empty;
            };
            if (clipped.isEmpty()) {
                return Self.empty;
            }

            const rows = clipped.height();
            const cols = clipped.width();
            const start = @as(usize, clipped.t) * self.stride + @as(usize, clipped.l);
            const end = @as(usize, clipped.b - 1) * self.stride + @as(usize, clipped.r);
            return .{
                .rows = rows,
                .cols = cols,
                .data = self.data[start..end],
                .stride = self.stride,
            };
        }

        /// Returns true if the image data is stored contiguously in memory.
        /// This is determined by checking if the `cols` field equals the `stride` field.
        /// When false, there is padding between rows.
        pub fn isContiguous(self: Self) bool {
            return self.cols == self.stride;
        }

        /// Checks if this image's buffer is aliased with (shares the same memory as) another image.
        /// Returns true if both images point to the same data buffer with the same length.
        /// This is useful for determining if in-place operations need a temporary buffer.
        ///
        /// Example usage:
        /// ```zig
        /// if (output.isAliased(input)) {
        ///     // Need temporary buffer for in-place operation
        ///     var temp = try Image(T).initLike(allocator, input);
        ///     defer temp.deinit(allocator);
        ///     // ... perform operation with temp, then copy to output
        /// }
        /// ```
        pub fn isAliased(self: Self, other: Self) bool {
            return self.data.ptr == other.data.ptr and self.data.len == other.data.len;
        }

        /// Creates a duplicate of the image with newly allocated memory.
        /// Correctly handles views by copying only the visible data.
        ///
        /// Example usage:
        /// ```zig
        /// var duped = try image.dupe(allocator);
        /// defer duped.deinit(allocator);
        /// ```
        pub fn dupe(self: Self, allocator: Allocator) !Self {
            const result = try Self.init(allocator, self.rows, self.cols);
            self.copy(result);
            return result;
        }

        /// Copies image data from `self` to `dst`, correctly handling views.
        /// If src and dst are the same object, does nothing (no-op).
        /// Uses fast @memcpy when neither image is a view, falls back to row-by-row copying otherwise.
        pub fn copy(self: Self, dst: Self) void {
            assert(self.hasSameShape(dst));
            if (self.data.ptr == dst.data.ptr) {
                return; // Same underlying data, nothing to copy
            }
            if (!self.isContiguous() or !dst.isContiguous()) {
                // Row-by-row copy for views
                for (0..self.rows) |r| {
                    const src_row_start = r * self.stride;
                    const dst_row_start = r * dst.stride;
                    @memcpy(
                        dst.data[dst_row_start .. dst_row_start + self.cols],
                        self.data[src_row_start .. src_row_start + self.cols],
                    );
                }
            } else {
                // Fast copy for non-views
                @memcpy(dst.data, self.data);
            }
        }

        /// Converts the image to a different pixel type, writing into a pre-allocated output image.
        /// The output image `out` must have the same dimensions as `self`.
        pub fn convertInto(self: Self, comptime TargetType: type, out: Image(TargetType)) void {
            assert(self.hasSameShape(out));
            if (comptime T == TargetType) {
                self.copy(out);
            } else {
                for (0..self.rows) |r| {
                    for (0..self.cols) |c| {
                        out.at(r, c).* = convertColor(TargetType, self.at(r, c).*);
                    }
                }
            }
        }

        /// Converts the image to a different pixel type.
        /// Allocates a new image with the target pixel type and converts each pixel using the color conversion system.
        ///
        /// Example usage:
        /// ```zig
        /// var rgba_image: Image(Rgba) = ...;
        /// var gray_image = try rgba_image.convert(u8, allocator);
        /// defer gray_image.deinit(allocator);
        /// ```
        pub fn convert(self: Self, comptime TargetType: type, allocator: Allocator) !Image(TargetType) {
            const result = try Image(TargetType).init(allocator, self.rows, self.cols);
            self.convertInto(TargetType, result);
            return result;
        }

        /// Returns the value at position row, col.  It assumes the coordinates are in bounds and
        /// triggers safety-checked undefined behavior when they aren't.
        pub inline fn at(self: Self, row: usize, col: usize) *T {
            assert(row < self.rows);
            assert(col < self.cols);
            return &self.data[row * self.stride + col];
        }

        /// Returns the optional value at row, col in the image.
        pub fn atOrNull(self: Self, row: i32, col: i32) ?*T {
            const irows: isize = @intCast(self.rows);
            const icols: isize = @intCast(self.cols);
            if (row < 0 or col < 0 or row >= irows or col >= icols) {
                return null;
            } else {
                return self.at(@intCast(row), @intCast(col));
            }
        }

        /// Creates a formatter for terminal display with custom options.
        /// Provides fine-grained control over output format, palette modes, and dithering.
        ///
        /// Display modes:
        /// - `.sgr`: Uses SGR (Select Graphic Rendition) with Unicode half-block characters (requires monospace font with U+2580 support)
        /// - `.braille`: Uses Braille patterns for 2x4 monochrome resolution (requires Unicode Braille support U+2800-U+28FF, converts to grayscale)
        /// - `.sixel`: Uses the sixel graphics protocol if supported
        /// - `.kitty`: Uses the kitty graphics protocol if supported
        /// - `.auto`: Automatically selects best available format: kitty -> sixel -> sgr
        ///
        /// Example:
        /// ```zig
        /// const img = try Image(Rgb).load(io, allocator, "test.png");
        /// std.debug.print("{f}", .{img.display(io, .sgr)});           // SGR with unicode half blocks
        /// std.debug.print("{f}", .{img.display(io, .{ .braille = .{ .threshold = 0.5 } })}); // 2x4 monochrome
        /// std.debug.print("{f}", .{img.display(io, .{ .sixel = .{ .palette_mode = .adaptive } })});
        /// std.debug.print("{f}", .{img.display(io, .{ .kitty = .default })});  // Kitty graphics protocol
        /// ```
        pub fn display(self: *const Self, io: std.Io, display_format: DisplayFormat) DisplayFormatter(T) {
            return DisplayFormatter(T){
                .image = self,
                .display_format = display_format,
                .io = io,
            };
        }

        /// Displays the image information: color type, rows and cols.
        pub fn format(self: Self, writer: *std.Io.Writer) std.Io.Writer.Error!void {
            const type_name: []const u8 = @typeName(T);
            if (std.mem.lastIndexOfScalar(u8, type_name, '.')) |pos| {
                try writer.print("Image({s}){{ .rows = {d}, .cols = {d} }}", .{ type_name[pos + 1 ..], self.rows, self.cols });
            } else {
                try writer.print("Image({s}){{ .rows = {d}, .cols = {d} }}", .{ type_name, self.rows, self.cols });
            }
        }

        /// Flips an image from left to right (mirror effect).
        pub fn flipLeftRight(self: Self) void {
            return Transform(T).flipLeftRight(self);
        }

        /// Flips an image from top to bottom (upside down effect).
        pub fn flipTopBottom(self: Self) void {
            return Transform(T).flipTopBottom(self);
        }

        /// Inverts the colors of an image in-place.
        /// For grayscale (u8): inverts as 255 - value
        /// For RGB colors: inverts each channel as 255 - channel
        /// For RGBA colors: inverts RGB channels but preserves alpha
        pub fn invert(self: Self) void {
            if (T == u8) {
                for (0..self.rows) |r| {
                    for (0..self.cols) |c| {
                        const pixel = self.at(r, c);
                        pixel.* = 255 - pixel.*;
                    }
                }
            } else if (@hasDecl(T, "invert")) {
                for (0..self.rows) |r| {
                    for (0..self.cols) |c| {
                        const pixel = self.at(r, c);
                        pixel.* = pixel.*.invert();
                    }
                }
            } else {
                @compileError("invert() requires pixel types with an invert() method or u8 grayscale pixels");
            }
        }

        /// Performs interpolation at position x, y using the specified method.
        /// Returns `null` if the coordinates are outside valid bounds for the chosen method.
        pub fn interpolate(self: Self, x: f32, y: f32, method: Interpolation) ?T {
            return interpolation.interpolate(T, self, x, y, method);
        }

        /// Resizes an image to fit in out, using the specified interpolation method.
        /// The output image must have the desired dimensions pre-allocated.
        /// Note: allocator is used for temporary buffers during RGB/RGBA channel processing.
        pub fn resize(self: Self, allocator: Allocator, out: Self, method: Interpolation) !void {
            try interpolation.resize(T, allocator, self, out, method);
        }

        /// Scales the image by the given factor using the specified interpolation method.
        /// A factor > 1.0 enlarges the image, < 1.0 shrinks it.
        /// The caller is responsible for calling deinit() on the returned image.
        pub fn scale(self: Self, allocator: Allocator, factor: f32, method: Interpolation) !Self {
            if (factor <= 0) return error.InvalidScaleFactor;

            const new_rows: u32 = @intFromFloat(@round(@as(f32, @floatFromInt(self.rows)) * factor));
            const new_cols: u32 = @intFromFloat(@round(@as(f32, @floatFromInt(self.cols)) * factor));

            if (new_rows == 0 or new_cols == 0) return error.InvalidDimensions;

            const scaled = try Self.init(allocator, new_rows, new_cols);
            try self.resize(allocator, scaled, method);
            return scaled;
        }

        /// Resizes an image to fit within the output dimensions while preserving aspect ratio.
        /// The image is centered with black/zero padding around it (letterboxing).
        /// Returns a rectangle describing the area containing the actual image content.
        pub fn letterbox(self: Self, allocator: Allocator, out: *Self, method: Interpolation) !Rectangle(u32) {
            return Transform(T).letterbox(self, allocator, out, method);
        }

        /// Rotates the image by `angle` (in radians) around its center.
        /// Returns a new image with optimal dimensions to fit the rotated content.
        /// The caller is responsible for calling deinit() on the returned image.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for the rotated image's data.
        /// - `angle`: The rotation angle in radians.
        /// - `method`: The interpolation method to use for sampling pixels.
        ///
        /// Example usage:
        /// ```zig
        /// var rotated = try image.rotate(allocator, std.math.pi / 4.0, .bilinear);
        /// defer rotated.deinit(allocator);
        /// ```
        pub fn rotate(self: Self, allocator: Allocator, angle: f32, method: Interpolation) !Self {
            return Transform(T).rotate(self, allocator, angle, method);
        }

        /// Crops a rectangular region from the image.
        /// If the specified `rectangle` is not fully contained within the image, the out-of-bounds
        /// areas in the output are filled with zeroed pixels (e.g., black/transparent).
        /// Returns a new image containing the cropped region.
        /// The caller is responsible for calling deinit() on the returned image.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for the cropped image's data.
        /// - `rectangle`: The `Rectangle(f32)` defining the region to crop. Coordinates will be rounded.
        ///
        /// Example usage:
        /// ```zig
        /// var chip = try image.crop(allocator, .{ .l = 10, .t = 10, .r = 100, .b = 100 });
        /// defer chip.deinit(allocator);
        /// ```
        pub fn crop(self: Self, allocator: Allocator, rectangle: Rectangle(f32)) !Self {
            return Transform(T).crop(self, allocator, rectangle);
        }

        /// Extracts a rotated rectangular region from the image and resamples it into `out`.
        ///
        /// Parameters:
        /// - `rect`: Axis-aligned rectangle (in source image coordinates) defining the region before rotation.
        /// - `angle`: Rotation angle in radians (counter-clockwise) applied around `rect` center.
        /// - `out`: Pre-allocated destination image that defines the output size. The extracted content is
        ///          resampled to exactly fill this image using `method`.
        /// - `method`: Interpolation method used when sampling from the source.
        ///
        /// Notes:
        /// - Out-of-bounds samples are filled with zeroed pixels (e.g., black/transparent).
        /// - `out` can be a view; strides are respected via `at()` accessors.
        /// - Optimized fast path for axis-aligned crops when angle is 0 and dimensions match.
        pub fn extract(self: Self, rect: Rectangle(f32), angle: f32, out: Self, method: Interpolation) void {
            return Transform(T).extract(self, rect, angle, out, method);
        }

        /// Inserts a source image into this image at the specified rectangle with rotation.
        ///
        /// This is the complement to `extract`. While `extract` pulls a region out of an image,
        /// `insert` places a source image into a destination region.
        ///
        /// Parameters:
        /// - `source`: The image to insert into self. Can be any Image type.
        /// - `rect`: Destination rectangle (in self's coordinates) where source will be placed.
        /// - `angle`: Rotation angle in radians (counter-clockwise) applied around `rect` center.
        /// - `method`: Interpolation method used when sampling from the source.
        /// - `blend_mode`: Blending mode to apply while inserting the image.
        ///
        /// Notes:
        /// - The source image is scaled to fit the destination rectangle.
        /// - For Image(Rgba) sources, alpha blending is applied using the specified blend mode.
        /// - When the source is not RGBA, pixels are copied directly.
        /// - Pixels outside the source bounds are not modified in self.
        /// - This method mutates self in-place.
        pub fn insert(self: *Self, source: anytype, rect: Rectangle(f32), angle: f32, method: Interpolation, blend_mode: Blending) void {
            return Transform(T).insert(self, source, rect, angle, method, blend_mode);
        }

        /// Applies a geometric transform to the image using the specified interpolation method.
        ///
        /// This method warps an image using a geometric transform (Similarity, Affine, or Projective).
        /// For each pixel in the output image, it applies the transform to find the corresponding
        /// location in the source image and samples using the specified interpolation method.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for the output image.
        /// - `transform`: A geometric transform object (SimilarityTransform, AffineTransform, or ProjectiveTransform).
        /// - `method`: Interpolation method for sampling pixels.
        /// - `out`: Output image. If empty, will be allocated with specified dimensions.
        /// - `out_rows`: Number of rows in the output image.
        /// - `out_cols`: Number of columns in the output image.
        ///
        /// Example usage:
        /// ```zig
        /// const transform = try SimilarityTransform(f32).init(from_points, to_points);
        /// var warped: Image(T) = .empty;
        /// try image.warp(allocator, transform, .bilinear, &warped, 512, 512);
        /// defer warped.deinit(allocator);
        /// ```
        pub fn warp(self: Self, allocator: Allocator, transform: anytype, method: Interpolation, out: *Self, out_rows: u32, out_cols: u32) !void {
            return Transform(T).warp(self, allocator, transform, method, out, out_rows, out_cols);
        }

        /// Computes the integral image, also known as a summed-area table (SAT), of `self`.
        /// For multi-channel images (e.g., structs like `Rgba`), it computes a per-channel
        /// integral image, storing the result as an array of floats per pixel in the output `integral` image.
        /// Uses SIMD optimizations for improved performance with a two-pass approach.
        pub fn integral(
            self: Self,
            allocator: Allocator,
            planes: *Self.Integral.Planes,
        ) !void {
            return Self.Integral.compute(self, allocator, planes);
        }

        /// Computes a blurred version of `self` using a box blur algorithm, efficiently implemented
        /// using an integral image. The `radius` parameter determines the size of the box window.
        /// This function is optimized using SIMD instructions for performance where applicable.
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn boxBlur(self: Self, allocator: Allocator, radius: u32, out: Self) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            if (radius == 0) {
                self.copy(out);
                return;
            }

            var planes: Self.Integral.Planes = .init();
            defer planes.deinit(allocator);
            try Self.Integral.compute(self, allocator, &planes);
            try Self.Integral.boxBlur(&planes, allocator, self, out, radius);
        }

        /// Applies a median blur using a square window with the given radius.
        /// Radius specifies half the window size; window size = `radius * 2 + 1`.
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn medianBlur(self: Self, allocator: Allocator, radius: usize, out: Self) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try OrderStatisticBlurOps(T).medianBlur(self, allocator, radius, out);
        }

        /// Applies a percentile blur (order-statistic filter) with the given percentile fraction.
        /// Percentile must be in the range [0, 1]; 0.5 corresponds to a median blur.
        ///
        /// Useful when you want fine-grained control over which ranked pixel is kept from the
        /// neighborhood. For example, `percentile = 0.1` can suppress bright outliers while
        /// retaining much of the local structure.
        ///
        /// ```zig
        /// var robust = try Image(u8).initLike(allocator, image);
        /// defer robust.deinit(allocator);
        /// try image.percentileBlur(allocator, 2, 0.1, .mirror, robust);
        /// ```
        pub fn percentileBlur(
            self: Self,
            allocator: Allocator,
            radius: usize,
            percentile: f64,
            border: BorderMode,
            out: Self,
        ) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try OrderStatisticBlurOps(T).percentileBlur(self, allocator, radius, percentile, border, out);
        }

        /// Applies a minimum blur (percentile zero) over a square window with the given radius.
        ///
        /// This is the morphological *erosion* operator â€“ great for removing "salt" noise or
        /// shrinking bright speckles while leaving darker structures intact.
        ///
        /// ```zig
        /// var denoised = try Image(u8).initLike(allocator, image);
        /// defer denoised.deinit(allocator);
        /// try image.minBlur(allocator, 1, .mirror, denoised);
        /// ```
        pub fn minBlur(
            self: Self,
            allocator: Allocator,
            radius: usize,
            border: BorderMode,
            out: Self,
        ) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try OrderStatisticBlurOps(T).minBlur(self, allocator, radius, border, out);
        }

        /// Applies a maximum blur (percentile one) over a square window with the given radius.
        ///
        /// Equivalent to morphological *dilation*. It can fill in small gaps or expand highlights,
        /// which is helpful for creating masks or closing thin cracks.
        ///
        /// ```zig
        /// var mask = try Image(u8).initLike(allocator, image);
        /// defer mask.deinit(allocator);
        /// try image.maxBlur(allocator, 2, .mirror, mask);
        /// ```
        pub fn maxBlur(
            self: Self,
            allocator: Allocator,
            radius: usize,
            border: BorderMode,
            out: Self,
        ) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try OrderStatisticBlurOps(T).maxBlur(self, allocator, radius, border, out);
        }

        /// Applies a midpoint blur that averages the minimum and maximum values within the window.
        ///
        /// Midpoint filtering is a fast way to reduce random impulse noise while retaining thin
        /// edges. Think of it as a compromise between min and max filters.
        ///
        /// ```zig
        /// var softened = try Image(u8).initLike(allocator, image);
        /// defer softened.deinit(allocator);
        /// try image.midpointBlur(allocator, 1, .mirror, softened);
        /// ```
        pub fn midpointBlur(
            self: Self,
            allocator: Allocator,
            radius: usize,
            border: BorderMode,
            out: Self,
        ) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try OrderStatisticBlurOps(T).midpointBlur(self, allocator, radius, border, out);
        }

        /// Applies an alpha-trimmed mean blur, discarding a fraction of the lowest and highest pixels.
        /// `trim_fraction` must be in [0, 0.5).
        ///
        /// This filter is useful when you want the smoothness of an average but need robustness to
        /// extremes (for example, sensor hot pixels or specular highlights). Trimming 10% from each
        /// tail delivers a strong denoise without smearing edges.
        ///
        /// ```zig
        /// var robust_mean = try Image(Rgba).initLike(allocator, color_image);
        /// defer robust_mean.deinit(allocator);
        /// try color_image.alphaTrimmedMeanBlur(allocator, 2, 0.1, .mirror, robust_mean);
        /// ```
        pub fn alphaTrimmedMeanBlur(
            self: Self,
            allocator: Allocator,
            radius: usize,
            trim_fraction: f64,
            border: BorderMode,
            out: Self,
        ) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try OrderStatisticBlurOps(T).alphaTrimmedMeanBlur(self, allocator, radius, trim_fraction, border, out);
        }

        /// Computes a sharpened version of `self` by enhancing edges.
        /// It uses the formula `sharpened = 2 * original - blurred`, where `blurred` is a box-blurred
        /// version of the original image (calculated efficiently using an integral image).
        /// The `radius` parameter controls the size of the blur. This operation effectively
        /// increases the contrast at edges. SIMD optimizations are used for performance where applicable.
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn sharpen(self: Self, allocator: Allocator, radius: usize, out: Self) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            if (radius == 0) {
                self.copy(out);
                return;
            }

            // Compute integral planes and apply sharpening
            var planes = Self.Integral.Planes.init();
            defer planes.deinit(allocator);
            try Self.Integral.compute(self, allocator, &planes);
            Self.Integral.sharpen(&planes, self, out, radius);
        }

        /// Automatically adjusts the contrast of an image by stretching the intensity range.
        ///
        /// This function analyzes the histogram of the image and remaps pixel values so that
        /// the darkest pixels become black (0) and the brightest become white (255), with
        /// intermediate values scaled proportionally.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for the new image
        /// - `cutoff`: Percentage of pixels to ignore at the extremes (0-100).
        ///             For example, 2.0 ignores the darkest and brightest 2% of pixels,
        ///             which helps remove outliers.
        ///
        /// Adjusts contrast by stretching the intensity range. Modifies in-place.
        /// Parameters:
        /// - `cutoff`: Fraction of pixels to ignore from each end (0.0 to 0.5)
        pub fn autocontrast(self: Self, cutoff: f32) !void {
            return Enhancement(T).autocontrast(self, cutoff);
        }

        /// Equalizes the histogram of an image to improve contrast.
        ///
        /// This function redistributes pixel intensities to achieve a more uniform histogram,
        /// which typically enhances contrast in images with poor contrast or uneven lighting.
        /// The technique maps the cumulative distribution function (CDF) of pixel values to
        /// create a more even spread of intensities across the full range.
        ///
        /// For color images (RGB/RGBA), each channel is equalized independently.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for the new image
        ///
        /// Returns: A new image with equalized histogram
        ///
        /// Example usage:
        /// ```zig
        /// var img = try Image(u8).load(io, allocator, "low_contrast.png");
        /// var equalized = try img.equalize(allocator);
        /// defer equalized.deinit(allocator);
        /// ```
        /// Equalizes the histogram to improve contrast. Modifies in-place.
        pub fn equalize(self: Self) void {
            return Enhancement(T).equalize(self);
        }

        /// Computes Otsu's threshold and produces a binary image.
        /// Returns the threshold value that maximizes between-class variance.
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn thresholdOtsu(self: Self, allocator: Allocator, out: Image(u8)) !u8 {
            if (comptime T != u8) {
                @compileError("thresholdOtsu is only available for Image(u8)");
            }
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            return binary.Binary.thresholdOtsu(self, allocator, out);
        }

        /// Applies adaptive mean thresholding using a square window defined by `radius`.
        /// Each pixel is compared against the mean of its local neighborhood minus `c`.
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn thresholdAdaptiveMean(self: Self, allocator: Allocator, radius: usize, c: f32, out: Image(u8)) !void {
            if (comptime T != u8) {
                @compileError("thresholdAdaptiveMean is only available for Image(u8)");
            }
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            return binary.Binary.thresholdAdaptiveMean(self, allocator, radius, c, out);
        }

        /// Performs binary dilation using the provided structuring element.
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn dilateBinary(self: Self, allocator: Allocator, kernel: BinaryKernel, iterations: usize, out: Image(u8)) !void {
            if (comptime T != u8) {
                @compileError("dilateBinary is only available for Image(u8)");
            }
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try binary.Binary.dilate(self, allocator, kernel, iterations, out);
        }

        /// Performs binary erosion using the provided structuring element.
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn erodeBinary(self: Self, allocator: Allocator, kernel: BinaryKernel, iterations: usize, out: Image(u8)) !void {
            if (comptime T != u8) {
                @compileError("erodeBinary is only available for Image(u8)");
            }
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try binary.Binary.erode(self, allocator, kernel, iterations, out);
        }

        /// Performs a binary opening (erosion followed by dilation).
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn openBinary(self: Self, allocator: Allocator, kernel: BinaryKernel, iterations: usize, out: Image(u8)) !void {
            if (comptime T != u8) {
                @compileError("openBinary is only available for Image(u8)");
            }
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try binary.Binary.open(self, allocator, kernel, iterations, out);
        }

        /// Performs a binary closing (dilation followed by erosion).
        /// The output image must be pre-allocated with the same dimensions as the input.
        pub fn closeBinary(self: Self, allocator: Allocator, kernel: BinaryKernel, iterations: usize, out: Image(u8)) !void {
            if (comptime T != u8) {
                @compileError("closeBinary is only available for Image(u8)");
            }
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            try binary.Binary.close(self, allocator, kernel, iterations, out);
        }

        /// Applies a 2D convolution with the given kernel to the image.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for temporary buffers.
        /// - `kernel`: A 2D array representing the convolution kernel.
        /// - `border`: How to handle pixels at the image borders.
        /// - `out`: The output image (must be pre-allocated with same dimensions).
        pub fn convolve(self: Self, allocator: Allocator, kernel: anytype, border: BorderMode, out: Self) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            return convolution.convolve(T, self, allocator, kernel, border, out);
        }

        /// Performs separable convolution using two 1D kernels (horizontal and vertical).
        /// This is much more efficient for separable filters like Gaussian blur.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for temporary buffers.
        /// - `kernel_x`: Horizontal (column) kernel.
        /// - `kernel_y`: Vertical (row) kernel.
        /// - `border`: How to handle image borders.
        /// - `out`: The output image (must be pre-allocated with same dimensions).
        pub fn convolveSeparable(self: Self, allocator: Allocator, kernel_x: []const f32, kernel_y: []const f32, border: BorderMode, out: Self) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            return convolution.convolveSeparable(T, self, allocator, kernel_x, kernel_y, border, out);
        }

        /// Applies Gaussian blur to the image using separable convolution.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for temporary buffers.
        /// - `sigma`: Standard deviation of the Gaussian kernel.
        /// - `out`: The output blurred image (must be pre-allocated with same dimensions).
        pub fn gaussianBlur(self: Self, allocator: Allocator, sigma: f32, out: Self) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            // sigma == 0 means no blur; just copy input to output
            if (sigma == 0) {
                self.copy(out);
                return;
            }
            if (sigma < 0) return error.InvalidSigma;

            // Calculate kernel size (3 sigma on each side)
            const radius = @as(usize, @intFromFloat(@ceil(3.0 * sigma)));
            const kernel_size = 2 * radius + 1;

            // Generate 1D Gaussian kernel
            var kernel = try allocator.alloc(f32, kernel_size);
            defer allocator.free(kernel);

            var sum: f32 = 0;
            for (0..kernel_size) |i| {
                const x = @as(f32, @floatFromInt(i)) - @as(f32, @floatFromInt(radius));
                kernel[i] = @exp(-(x * x) / (2.0 * sigma * sigma));
                sum += kernel[i];
            }

            // Normalize kernel
            for (kernel) |*k| {
                k.* /= sum;
            }

            // Apply separable convolution
            try convolution.convolveSeparable(T, self, allocator, kernel, kernel, .mirror, out);
        }

        /// Applies the Sobel filter to `self` to perform edge detection.
        /// The output is a grayscale image representing the magnitude of gradients at each pixel.
        /// The output image must be pre-allocated with the same dimensions as the input.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for temporary buffers.
        /// - `out`: Output image that will be filled with the Sobel magnitude image.
        pub fn sobel(self: Self, allocator: Allocator, out: Image(u8)) !void {
            if (self.rows != out.rows or self.cols != out.cols) {
                return error.DimensionMismatch;
            }
            return Edges(T).sobel(self, allocator, out);
        }

        /// Applies the Shen-Castan edge detection algorithm using the Infinite Symmetric
        /// Exponential Filter (ISEF). This algorithm provides superior edge localization
        /// and noise handling compared to traditional methods.
        /// The output image must be pre-allocated with the same dimensions as the input.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for temporary buffers.
        /// - `opts`: Shen-Castan options (smoothing, thresholds, thinning, hysteresis).
        /// - `out`: Output edge map as binary image (0 or 255).
        pub fn shenCastan(
            self: Self,
            allocator: Allocator,
            opts: ShenCastan,
            out: Image(u8),
        ) !void {
            if (self.rows != out.rows or self.cols != out.cols) {
                return error.DimensionMismatch;
            }
            return Edges(T).shenCastan(self, allocator, opts, out);
        }

        /// Applies the Canny edge detection algorithm, a classic multi-stage edge detector.
        /// This algorithm produces thin, well-localized edges with good noise suppression.
        ///
        /// The Canny algorithm consists of five main steps:
        /// 1. Gaussian smoothing to reduce noise
        /// 2. Gradient computation using Sobel operators
        /// 3. Non-maximum suppression to thin edges
        /// 4. Double thresholding to classify strong and weak edges
        /// 5. Edge tracking by hysteresis to link edges
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for temporary buffers.
        /// - `sigma`: Standard deviation for Gaussian blur (typical: 1.0-2.0).
        /// - `low_threshold`: Lower threshold for hysteresis (0-255).
        /// - `high_threshold`: Upper threshold for hysteresis (0-255).
        /// - `out`: Output edge map as binary image (0 or 255).
        ///
        /// Note: `high_threshold` should be 2-3x larger than `low_threshold` for best results.
        ///
        /// Example:
        /// ```zig
        /// var edges = try Image(u8).initLike(allocator, image);
        /// defer edges.deinit(allocator);
        /// try image.canny(allocator, 1.4, 50, 150, edges);
        /// ```
        pub fn canny(
            self: Self,
            allocator: Allocator,
            sigma: f32,
            low_threshold: f32,
            high_threshold: f32,
            out: Image(u8),
        ) !void {
            if (self.rows != out.rows or self.cols != out.cols) {
                return error.DimensionMismatch;
            }
            return Edges(T).canny(self, allocator, sigma, low_threshold, high_threshold, out);
        }

        /// Applies motion blur effect to the image.
        /// Supports linear motion blur (camera/object movement) and radial blur (zoom/spin effects).
        /// The output image must be pre-allocated with the same dimensions as the input.
        ///
        /// Parameters:
        /// - `allocator`: The allocator to use for temporary buffers.
        /// - `motion`: Type and parameters of motion blur to apply.
        /// - `out`: Output image containing the motion blurred result.
        ///
        /// Example usage:
        /// ```zig
        /// var out = try Image(Rgb).initLike(allocator, image);
        /// defer out.deinit(allocator);
        ///
        /// // Linear motion blur
        /// try image.motionBlur(allocator, .{ .linear = .{ .angle = 0, .distance = 30 }}, out);
        /// ```
        pub fn motionBlur(self: Self, allocator: Allocator, motion: MotionBlur, out: Self) !void {
            if (!self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }
            switch (motion) {
                .linear => |params| try MotionBlurOps(T).linear(self, allocator, params.angle, params.distance, out),
                .radial_zoom => |params| try MotionBlurOps(T).radial(self, allocator, params.center_x, params.center_y, params.strength, .zoom, out),
                .radial_spin => |params| try MotionBlurOps(T).radial(self, allocator, params.center_x, params.center_y, params.strength, .spin, out),
            }
        }

        /// Calculates the Peak Signal-to-Noise Ratio (PSNR) between two images.
        /// PSNR is a measure of image fidelity, with higher values indicating better quality.
        /// Returns `inf` when images are identical (mean squared error = 0).
        ///
        /// Returns `error.DimensionMismatch` if the images have different dimensions.
        ///
        /// This wrapper is type-agnostic and works with any pixel type:
        /// - Scalars (u8, f32, etc.)
        /// - Structs (Rgb, Rgba, etc.)
        /// - Arrays ([3]u8, [4]f32, etc.)
        pub fn psnr(self: Self, other: Self) !f64 {
            return metrics.psnr(T, self, other);
        }

        /// Calculates the Structural Similarity Index (SSIM) between two images.
        /// SSIM is a perceptual metric that measures structural similarity, with values in [0, 1].
        /// 1.0 = identical images, 0.0 = completely different.
        ///
        /// This is more perceptually meaningful than PSNR for image quality assessment.
        /// Uses an 11x11 Gaussian window with Ïƒ=1.5, as recommended in the original paper.
        ///
        /// Reference: Wang et al., "Image Quality Assessment: From Error Visibility to Structural Similarity",
        /// IEEE Transactions on Image Processing, 2004.
        ///
        /// ## Implementation Notes:
        /// - For RGB/RGBA pixels: converts to luminance using Rec. 709 weights (ignores alpha)
        /// - For grayscale pixels: uses pixel value directly
        /// - For float pixels: assumes normalized [0, 1] range
        /// - Uses "valid" windowing: drops 5-pixel border (no padding/reflection)
        ///
        /// Returns an error if the images have different dimensions or are too small (< 11x11).
        pub fn ssim(self: Self, other: Self) !f64 {
            return metrics.ssim(T, self, other);
        }

        /// Specifies the mode for computing the difference between two images.
        pub const DiffMode = union(enum) {
            /// Computes the absolute difference per channel: |a - b|.
            absolute,
            /// Computes a binary mask where each pixel is either the maximum value (255 for u8)
            /// or zero, based on whether the difference exceeds the provided threshold.
            binary: f32,
        };

        /// Computes the difference between `self` and `other` per pixel/channel.
        /// The result is stored in `out`, which must have the same dimensions.
        ///
        /// Modes:
        /// - .absolute: out = |self - other|
        /// - .binary(t): if |self - other| > t then max_val else 0
        pub fn diff(self: Self, other: Self, out: Self, mode: DiffMode) !void {
            if (!self.hasSameShape(other) or !self.hasSameShape(out)) {
                return error.DimensionMismatch;
            }

            for (0..self.rows) |r| {
                for (0..self.cols) |c| {
                    const p1 = self.at(r, c).*;
                    const p2 = other.at(r, c).*;
                    const dest = out.at(r, c);

                    switch (@typeInfo(T)) {
                        .int => {
                            const d_int = if (p1 > p2) p1 - p2 else p2 - p1;
                            switch (mode) {
                                .absolute => dest.* = d_int,
                                .binary => |t| {
                                    dest.* = if (@as(f32, @floatFromInt(d_int)) > t) std.math.maxInt(T) else 0;
                                },
                            }
                        },
                        .float => {
                            const d_float = @abs(p1 - p2);
                            switch (mode) {
                                .absolute => dest.* = d_float,
                                .binary => |t| {
                                    dest.* = if (d_float > t) 1.0 else 0.0;
                                },
                            }
                        },
                        .@"struct" => {
                            switch (mode) {
                                .absolute => {
                                    inline for (std.meta.fields(T)) |field| {
                                        const v1 = @field(p1, field.name);
                                        const v2 = @field(p2, field.name);
                                        switch (@typeInfo(field.type)) {
                                            .int => {
                                                @field(dest.*, field.name) = if (v1 > v2) v1 - v2 else v2 - v1;
                                            },
                                            .float => {
                                                @field(dest.*, field.name) = @abs(v1 - v2);
                                            },
                                            else => @compileError("Unsupported field type for diff"),
                                        }
                                    }
                                },
                                .binary => |t| {
                                    var is_diff = false;
                                    inline for (std.meta.fields(T)) |field| {
                                        const v1 = @field(p1, field.name);
                                        const v2 = @field(p2, field.name);
                                        const d = switch (@typeInfo(field.type)) {
                                            .int => @as(f32, @floatFromInt(if (v1 > v2) v1 - v2 else v2 - v1)),
                                            .float => @abs(v1 - v2),
                                            else => 0,
                                        };
                                        if (d > t) {
                                            is_diff = true;
                                            break;
                                        }
                                    }

                                    // For binary mode in struct (e.g. RGB), if any channel differs, set all to max
                                    inline for (std.meta.fields(T)) |field| {
                                        const max_v = switch (@typeInfo(field.type)) {
                                            .int => std.math.maxInt(field.type),
                                            .float => 1.0,
                                            else => unreachable,
                                        };
                                        @field(dest.*, field.name) = if (is_diff) max_v else 0;
                                    }
                                },
                            }
                        },
                        .array => |info| {
                            switch (mode) {
                                .absolute => {
                                    for (0..info.len) |i| {
                                        const v1 = p1[i];
                                        const v2 = p2[i];
                                        switch (@typeInfo(info.child)) {
                                            .int => dest.*[i] = if (v1 > v2) v1 - v2 else v2 - v1,
                                            .float => dest.*[i] = @abs(v1 - v2),
                                            else => @compileError("Unsupported array child type for diff"),
                                        }
                                    }
                                },
                                .binary => |t| {
                                    var is_diff = false;
                                    for (0..info.len) |i| {
                                        const v1 = p1[i];
                                        const v2 = p2[i];
                                        const d = switch (@typeInfo(info.child)) {
                                            .int => @as(f32, @floatFromInt(if (v1 > v2) v1 - v2 else v2 - v1)),
                                            .float => @abs(v1 - v2),
                                            else => 0,
                                        };
                                        if (d > t) {
                                            is_diff = true;
                                            break;
                                        }
                                    }
                                    const max_v = switch (@typeInfo(info.child)) {
                                        .int => std.math.maxInt(info.child),
                                        .float => 1.0,
                                        else => unreachable,
                                    };
                                    for (0..info.len) |i| {
                                        dest.*[i] = if (is_diff) max_v else 0;
                                    }
                                },
                            }
                        },
                        else => @compileError("Unsupported pixel type for diff"),
                    }
                }
            }
        }

        /// Computes the mean absolute pixel error normalized by the maximum channel value
        /// (e.g. 255 for `u8`). Requires both images to share the same dimensions.
        pub fn meanPixelError(self: Self, other: Self) !f64 {
            return metrics.meanPixelError(T, self, other);
        }

        pub fn pixels(self: Self) PixelIterator(T) {
            return .{
                .data = self.data,
                .cols = self.cols,
                .stride = self.stride,
                .rows = self.rows,
            };
        }

        /// Computes a histogram of the image pixel values.
        /// Supported types: u8, Rgb, Rgba
        /// Returns a Histogram struct with channel-specific bins.
        pub fn histogram(self: Self) Histogram(T) {
            var hist: Histogram(T) = .init();

            var iter = self.pixels();
            while (iter.next()) |pixel| {
                switch (T) {
                    u8 => {
                        hist.values[pixel.*] += 1;
                    },
                    Rgb => {
                        hist.r[pixel.r] += 1;
                        hist.g[pixel.g] += 1;
                        hist.b[pixel.b] += 1;
                    },
                    Rgba => {
                        hist.r[pixel.r] += 1;
                        hist.g[pixel.g] += 1;
                        hist.b[pixel.b] += 1;
                        hist.a[pixel.a] += 1;
                    },
                    else => @compileError("histogram() only supports u8, Rgb, and Rgba types"),
                }
            }
            return hist;
        }
    };
}

// Run all tests
test {
    _ = @import("image/PixelIterator.zig");
    _ = @import("image/format.zig");
    _ = @import("image/display.zig");
    _ = @import("image/tests/integral.zig");
    _ = @import("image/tests/filters.zig");
    _ = @import("image/tests/transforms.zig");
    _ = @import("image/tests/display.zig");
    _ = @import("image/tests/interpolation.zig");
    _ = @import("image/tests/resize.zig");
    _ = @import("image/tests/psnr.zig");
    _ = @import("image/tests/shen_castan.zig");
    _ = @import("image/tests/binary.zig");
}
